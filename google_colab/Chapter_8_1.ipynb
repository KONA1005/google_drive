{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_8_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMb61jEuiyL7Jy8WDDv7mdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KONA1005/google_drive/blob/main/google_colab/Chapter_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망\n",
        "- 422p\n",
        "- 로지스틱 회귀 ( 일반 머신러닝 모형) : 81% 정확도 \n",
        "- 인공신경망 도입 (딥러닝 초기모형) : 87% 정확도\n",
        "- 합성곱(convolution, CNN) 이미지의 특성을 잡아내는(뽑는) \n",
        "  + 금일 코드 보다는 주요 용어 정리를 하는데 주력\n",
        "  + 발전사 : alexnet 2012 -> resnet -> efficientnet\n",
        "  + 핵심 : **채널, 이미지의 넓이, 크기(파라미터 튜닝)**\n",
        "  + Vision Transformer \n",
        "  \n",
        "- 비디오\n",
        "  + 객체인식(Object Detection)\n",
        "  + Yolo 논문\n",
        "\n",
        "- RNN / LSTM (자연어 처리)\n",
        "  + 구글에서 2017년에 Transformer논문 발표. 기가막힘\n",
        "****"
      ],
      "metadata": {
        "id": "JmnrflxiQ415"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱의 장점\n",
        "- 기존에는 무조건 1차원 배열에서만 연산이 가능\n",
        "- 2차원 배열에도 연산을 할 수 있도록 구현\n",
        "  + 선형대수를 공부해야 하나요?"
      ],
      "metadata": {
        "id": "PPyj4jW3c2r5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B-cbOxsQ1_O",
        "outputId": "05243168-7b31-4184-9c55-dcfaa84645d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fa2dd899250>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "keras.layers.Conv2D(10, kernel_size = (3,3), activation = 'relu') # 커널사이즈 조정 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 패딩의 목적\n",
        "- (뽑으려는)이미지 손실이 일어나면 안되기 때문에 배열의 크기를 조절하더라도 이미지 원 특성이 손실되는 것을 방지하는것"
      ],
      "metadata": {
        "id": "6_jXMfnZhk4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.layers.Conv2D(10, kernel_size = (3,3), \n",
        "                    activation = 'relu', padding= 'same', strides = 1)\n",
        "# strides 칸수 이동"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzzBBqW2h0G0",
        "outputId": "0ed943d2-6fc8-4f47-c0a2-dc171da70a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.convolutional.Conv2D at 0x7fa259dd2150>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 풀링\n",
        "- 값을 추출하는 것\n",
        "\n",
        "원래 100 * 100 이미지 -> (수치로) 주요 이미지의 특성만 뽑은 후, 원 이미지와 같게 만듬( 50*50 )\n"
      ],
      "metadata": {
        "id": "6fs53lcFi6IC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "437p\n",
        "- 1단계 : 이미지 데이터 입력\n",
        "- 2단계 :  합성곱 층 만들기\n",
        "  + 1. 필터 검. kernel_size + padding\n",
        "  + 2. 활성화 함수 진행\n",
        "  + 3. 각각의 특성맵 추출\n",
        "- 3단계 : 풀링층\n",
        "  + 최대풀링 (Max Pooling) 최댓값 뽑기\n",
        "  + 최종 특성맵\n",
        "- 위 과정을 계속 반복하는 것이 CNN 알고리즘\n",
        "- 4단계 :  밀집층(Fully Connected Layer)\n",
        "  + chapter 7 장에서 이미 배움\n",
        "- 5단계 :  분류 예측값을 산출(Softmax 활성화함수)\n",
        "\n",
        "\n",
        "주요 키워드 : **전이학습**(Transfer Learning) / 파인튜닝\n",
        "  + 캐글 경진대회\n",
        "  + 클래스 공부 필수\n"
      ],
      "metadata": {
        "id": "TtY_vZyrnWaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이학습\n",
        "- 하나의 작업을 위해 훈련된 모델을 유사 작업 수행 모델의 시작점으로 활용하는 딥러닝 접근법.\n",
        "- 거대한 데이터셋으로 학습한 가중치의 일부를 능력이 유사하거나 새로운 분야의 신경망에 복사한 후, 그 상태로 재학습을 수행하는 것을 의미"
      ],
      "metadata": {
        "id": "LVNi12gKr1RN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 필터 (Filter)\n",
        "\n",
        "필터에 **해당하는 특징이 데이터에 있는지**를 검출해주는 함수.\n",
        "\n",
        "이 필터를 기존의 데이터와 합성곱 연산을 진행하면 필터에 해당하는 특성을 갖고 있으면 결과 값으로 큰 값이 나오고, 특성을 가지지 않으면 결과값이 0에 가깝게 나오면서 입력데이터가 필터에 해당하는 특징을 갖고 있는지, 아닌지에 대한 여부를 알 수 있다.\n",
        "\n",
        "- 패딩 (Padding)\n",
        "\n",
        "합성곱 연산을 하기 이전, 입력데이터 주변을 **특정값으로 채워 늘리는** 것을 패딩(Padding)이라고 한다.\n",
        "\n",
        "패딩(Padding)은 주로 **출력 데이터의 크기를 조정할 목적으로 사용**한다. 합성곱 연산을 반복하다보면 어느 시점부터는 출력 데이터의 크기가 1이 되어 더이상 합성곱 연산을 진행할 수 없게 된다. 패딩(Padding)을 사용하여 입력데이터의 외각의 크기를 늘려 출력 데이터의 크기가 줄어드는 것을 방지한다.\n",
        "\n",
        "- 스트라이드 (Stride)\n",
        "\n",
        "Stride는 입력데이터에 필터를 적용할 때 이동할 간격을 조절하는, 즉 **필터가 이동할 간격**을 뜻한다. Stride의 값을 키우면 키울수록 출력 데이터의 크기는 작아지며 Padding은 크게하면 할수록 출력 크기가 커진다.\n",
        "\n",
        "- 풀링(Pooling)\n",
        "\n",
        "세로, 가로 방향의 공간을 줄이는 연산\n",
        "  + 특징 : 학습해야 할 매개변수가 없다, 채널수가 변하지 않는다, 입력의 변화에 영향을 적게 받는다.\n",
        "  \n",
        "파라미터를 줄이기 때문에 신경망의 표현력이 줄어들어 오버피팅을 억제하고 연산을 비교적 간단하게 만들어준다.\n"
      ],
      "metadata": {
        "id": "9uIrX6TyvE0b"
      }
    }
  ]
}